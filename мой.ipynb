{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PAfAz9Nbo4g2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11468,
     "status": "ok",
     "timestamp": 1765913377571,
     "user": {
      "displayName": "Jony",
      "userId": "17106676444710505921"
     },
     "user_tz": -300
    },
    "id": "PAfAz9Nbo4g2",
    "outputId": "0c6f798a-b460-4f26-f06f-88491b78328b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
      "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: gensim\n",
      "Successfully installed gensim-4.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa58750",
   "metadata": {
    "id": "6aa58750"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from gensim.models import FastText\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0575cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18162,
     "status": "ok",
     "timestamp": 1765913276422,
     "user": {
      "displayName": "Jony",
      "userId": "17106676444710505921"
     },
     "user_tz": -300
    },
    "id": "ce0575cd",
    "outputId": "0d0417d2-efd9-4513-f638-170338a5aa91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42da7ea6",
   "metadata": {
    "id": "42da7ea6"
   },
   "source": [
    "После того, как вы подключите Google Диск, вам нужно будет найти путь к вашему файлу `t_zz_text.csv`. Обычно файлы находятся в `/content/drive/My Drive/`. Например, если ваш файл находится в папке `project_2` на вашем Диске, путь будет `/content/drive/My Drive/project_2/t_zz_text.csv`. Замените `ПУТЬ_К_ВАШЕМУ_ФАЙЛУ_НА_GOOGLE_ДИСКЕ` на актуальный путь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c27bf",
   "metadata": {
    "id": "1c1c27bf"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/content/drive/MyDrive/t_zz_text.csv\", sep='|', on_bad_lines='warn')\n",
    "data.columns = data.columns.str.strip()\n",
    "data = data[data[\"transcript_operator_words\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5141d4",
   "metadata": {
    "id": "4c5141d4"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zа-яёқәһіұөү\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    tokens = text.split()\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "data[\"clean_text\"] = data[\"transcript_operator_words\"].astype(str).apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c93ba88",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 756374,
     "status": "ok",
     "timestamp": 1765914467924,
     "user": {
      "displayName": "Jony",
      "userId": "17106676444710505921"
     },
     "user_tz": -300
    },
    "id": "8c93ba88",
    "outputId": "1fb2592a-bcd3-485d-8340-bcd338eae63b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель не найдена или повреждена, создаем новую...\n"
     ]
    }
   ],
   "source": [
    "# model_path = \"/content/drive/MyDrive/fasttext_model.bin\"\n",
    "# model_exists = False\n",
    "\n",
    "# try:\n",
    "#     model_ft = FastText.load(model_path)\n",
    "#     print(\"Модель загружена, готовимся к дообучению...\")\n",
    "#     model_exists = True\n",
    "# except (FileNotFoundError, ValueError): # Catch ValueError in case of corrupted file\n",
    "#     print(\"Модель не найдена или повреждена, создаем новую...\")\n",
    "#     model_ft = FastText(vector_size=300, window=5, min_count=3, sg=1)\n",
    "\n",
    "# sentences = [t.split() for t in data[\"clean_text\"]]\n",
    "\n",
    "# if model_exists:\n",
    "#     model_ft.build_vocab(sentences, update=True) # Update existing vocabulary\n",
    "# else:\n",
    "#     model_ft.build_vocab(sentences) # Build new vocabulary (update=False by default)\n",
    "\n",
    "# model_ft.train(sentences, total_examples=len(sentences), epochs=10)\n",
    "# model_ft.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fbe97a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10749,
     "status": "ok",
     "timestamp": 1765915198941,
     "user": {
      "displayName": "Jony",
      "userId": "17106676444710505921"
     },
     "user_tz": -300
    },
    "id": "96fbe97a",
    "outputId": "efb1dd53-3473-4324-be77-10d9808a02a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText модель загружена\n"
     ]
    }
   ],
   "source": [
    "model_ft = FastText.load(\"/content/drive/MyDrive/fasttext_model.bin\")\n",
    "print(\"FastText модель загружена\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b04a63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11685,
     "status": "ok",
     "timestamp": 1765915220451,
     "user": {
      "displayName": "Jony",
      "userId": "17106676444710505921"
     },
     "user_tz": -300
    },
    "id": "64b04a63",
    "outputId": "feb43dec-eddb-4d44-e9cc-0e539a89e2b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding: 100%|██████████| 21007/21007 [00:11<00:00, 1815.78it/s]\n"
     ]
    }
   ],
   "source": [
    "def sentence_embedding(sentence, ft_model):\n",
    "    vectors = []\n",
    "    for w in sentence.split():\n",
    "        if w in ft_model.wv:\n",
    "            vectors.append(ft_model.wv[w])\n",
    "    if not vectors:\n",
    "        return np.zeros(ft_model.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "\n",
    "embeddings = np.array([sentence_embedding(t, model_ft) for t in tqdm(data[\"clean_text\"], desc=\"Embedding\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0510c73c",
   "metadata": {
    "id": "0510c73c"
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "data[\"sentiment\"] = kmeans.fit_predict(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926d8fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['sentiment'].values\n",
    "\n",
    "weights = class_weight.compute_class_weight(class_weight=\"balanced\", classes=np.unique(y), y=y)\n",
    "weights_dict = dict(enumerate(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32423afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469b5a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5353a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(class_weight=weights_dict, max_iter=1000)\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749e1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_scaled)\n",
    "y_prob = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34abaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pos_df = pd.read_excel(\n",
    "    r\"/content/drive/MyDrive/positive.csv\",\n",
    "    engine=\"openpyxl\"\n",
    ")\n",
    "\n",
    "neg_df = pd.read_excel(\n",
    "    r\"/content/drive/MyDrive/negative.csv\",\n",
    "    engine=\"openpyxl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ecc3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pos_df.columns)\n",
    "print(neg_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6737aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_texts(df):\n",
    "    col = df.select_dtypes(include=\"object\").columns[0]\n",
    "    return df[col].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c692e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_texts = extract_texts(pos_df)\n",
    "neg_texts = extract_texts(neg_df)\n",
    "\n",
    "print(\"Positive:\", len(pos_texts))\n",
    "print(\"Negative:\", len(neg_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c9fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_augment(sentence, ft_model, max_replace=2):\n",
    "    words = sentence.split()\n",
    "    if len(words) < 2:\n",
    "        return None\n",
    "\n",
    "    new_words = words.copy()\n",
    "    idxs = random.sample(range(len(words)), min(max_replace, len(words)))\n",
    "\n",
    "    for i in idxs:\n",
    "        w = words[i]\n",
    "        if w in ft_model.wv:\n",
    "            neighbors = [\n",
    "                n for n, s in ft_model.wv.most_similar(w, topn=5)\n",
    "                if s > 0.65\n",
    "            ]\n",
    "            if neighbors:\n",
    "                new_words[i] = random.choice(neighbors)\n",
    "\n",
    "    new_sent = \" \".join(new_words)\n",
    "\n",
    "    sim = 1 - cosine(\n",
    "        sentence_embedding(sentence, ft_model),\n",
    "        sentence_embedding(new_sent, ft_model)\n",
    "    )\n",
    "\n",
    "    return new_sent if sim < 0.95 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7329a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_corpus(texts, ft_model, n=2):\n",
    "    augmented = []\n",
    "    for t in texts:\n",
    "        for _ in range(n):\n",
    "            aug = fasttext_augment(t, ft_model)\n",
    "            if aug:\n",
    "                augmented.append(aug)\n",
    "    return list(set(augmented))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c262f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_pos = augment_corpus(pos_texts, model_ft, n=3)\n",
    "aug_neg = augment_corpus(neg_texts, model_ft, n=3)\n",
    "\n",
    "print(\"Aug pos:\", len(aug_pos))\n",
    "print(\"Aug neg:\", len(aug_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f57ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_labels = (\n",
    "    [\"positive\"] * (len(pos_texts) + len(aug_pos)) +\n",
    "    [\"negative\"] * (len(neg_texts) + len(aug_neg))\n",
    ")\n",
    "\n",
    "rag_embeddings = np.array([\n",
    "    sentence_embedding(t, model_ft)\n",
    "    for t in tqdm(rag_texts, desc=\"RAG Embedding\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3038211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_predict(text, threshold=0.75):\n",
    "    emb = sentence_embedding(preprocess_text(text), model_ft)\n",
    "    sims = [1 - cosine(emb, r) for r in rag_embeddings]\n",
    "    idx = np.argmax(sims)\n",
    "    if sims[idx] >= threshold:\n",
    "        return rag_labels[idx], sims[idx]\n",
    "    return None, sims[idx]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
